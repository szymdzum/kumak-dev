---
title: "CLI vs MCP on Chrome DevTools Protocol"
description: "I ran benchmarks comparing CLI tools against MCP servers for browser automation. 13x more token efficient with CLI. Here's what I found."
pubDate: 2025-11-23
category: "opinion"
tags: ["mcp", "cli", "browser-automation", "benchmarks", "ai-agents"]
keywords:
  [
    "Model Context Protocol",
    "MCP",
    "CLI tools",
    "browser automation",
    "Chrome DevTools Protocol",
    "AI agents",
    "token efficiency",
  ]
author: "Kumak"
showToc: true
featured: false
---

import TldrBox from '@components/TldrBox.astro';

<TldrBox>
CLI tools used 13x fewer tokens than MCP for identical browser automation tasks. MCP returns full accessibility snapshots; CLI returns targeted queries. The gap compounds with complex workflows.
</TldrBox>

Anthropic published an observation about [MCP and code execution](https://www.anthropic.com/engineering/code-execution-with-mcp): executable code in the filesystem might be more efficient for AI agents than protocol servers. Isn't that what CLI tools already are?

I tested this by comparing two approaches to browser automation:

- **CLI**: [bdg](https://github.com/szymdzum/browser-debugger-cli), a browser debugger CLI I built
- **MCP**: [Chrome DevTools MCP](https://github.com/ChromeDevTools/chrome-devtools-mcp), the official Chrome DevTools protocol server

Both interact with the Chrome DevTools Protocol. Same underlying capabilities. The question: does the interface matter?

## Methodology

Fresh Claude instance (Sonnet 4.5) with zero prior knowledge of either tool. Identical tasks across three websites: Hacker News (navigation, extraction), CodePen (inspection, screenshots), Amazon (product data, anti-bot stress test). No human guidance.

**Full methodology**: [BENCHMARK_PROMPT.md](https://github.com/szymdzum/browser-debugger-cli/blob/main/docs/benchmarks/BENCHMARK_PROMPT.md)

## Results

### Token Efficiency: 13x Difference

| Tool           | Total Tokens           | Per Test Average |
| -------------- | ---------------------- | ---------------- |
| **bdg (CLI)**  | 6,500                  | ~2,200           |
| **Chrome MCP** | 85,500                 | ~28,500          |
| **Difference** | **13x more efficient** |                  |

The gap comes from how each tool returns information:

**MCP**: Full accessibility snapshots. Every page state returns a complete accessibility tree. Amazon product page alone: **52,000 tokens** in one snapshot.

**CLI**: Targeted queries. `bdg dom query ".athing"` returns 30 Hacker News stories in 1,200 tokens.

### Command Count

| Test        | bdg Commands | MCP Calls |
| ----------- | ------------ | --------- |
| Hacker News | 11           | 8         |
| CodePen     | 6            | 5         |
| Amazon      | 4            | 3         |

MCP requires slightly fewer calls. But when one approach uses 13x more tokens per call, command count becomes less relevant.

### Discovery: Zero-Knowledge Learning

The most interesting result was watching how the agent learned each tool.

**bdg discovery path** (5 commands to first successful execution):

```bash
bdg --help --json
# Agent learns: 10 commands, exit codes, task mappings

bdg cdp --list
# Agent learns: 53 domains available

bdg cdp Network --list
# Agent learns: 39 methods in Network domain

bdg cdp --search cookie
bdg cdp Network.getCookies --describe
# Agent discovers parameters, return types, examples

bdg cdp Network.getCookies
# Successful execution
```

Zero external documentation. The tool taught itself through introspection.

**MCP discovery**: Requires understanding MCP protocol, parsing 10k+ token accessibility trees to find element UIDs, using UID-based selection from snapshots.

### Element Selection

**bdg**: Standard CSS selectors

```bash
bdg dom query ".athing"              # Hacker News stories
bdg dom query "#productTitle"        # Amazon product
bdg dom click "button[type=submit]"
```

**MCP**: UID-based from accessibility tree

```javascript
take_snapshot({}); // Returns 10k+ tokens
click({ uid: '1_28' }); // Must find UID in snapshot first
```

CSS selectors are familiar; UID-based selection is more robust for dynamic content. Trade-offs exist.

## Why the Gap Exists

**Return payload size**: MCP's accessibility snapshots include everything. CLI queries return only what you ask for. This is the primary driver of the 13x difference.

**Error handling**: CLI failures return structured errors with exit codes and suggestions. The agent can self-correct:

```bash
$ bdg dom click ".missing-button"
Error: Element not found: .missing-button
Exit code: 81 (user error)

Suggestions:
  - Verify selector: bdg dom query ".missing-button"
  - List all buttons: bdg dom query "button"
```

**Composability**: CLI tools integrate with Unix:

```bash
bdg peek --network | jq '.[] | select(.status >= 400)'
bdg dom query "button" | jq '.[0].nodeId' | xargs bdg dom click
```

If the tool doesn't provide exactly what you need, compose it with `jq`, `grep`, or `awk`. MCP servers require protocol extensions.

**Protocol access**: bdg exposes all 644 CDP methods across 53 domains. MCP servers expose curated subsets. Need `Profiler.startPreciseCoverage`? It's there via `bdg cdp Profiler.startPreciseCoverage`.

## Limitations

- **Small sample**: 3 websites
- **Single model**: Claude Sonnet 4.5 only
- **Specific scenarios**: Information extraction workflows
- **Bot detection**: Both tools faced blocks on some sites

The token efficiency advantage should apply equally to debugging workflows (console streaming, network inspection, profiling), but I didn't benchmark those specifically.

## Takeaway

For browser automation with AI agents, CLI tools proved 13x more token-efficient than MCP servers accessing the same underlying protocol. The difference comes from targeted queries vs. full snapshots, plus the ability to compose with Unix tools and access the complete CDP surface.

This isn't definitive. It's one data point. Your needs may differ.

**Full results**: [BENCHMARK_RESULTS_2025-11-23.md](https://github.com/szymdzum/browser-debugger-cli/blob/main/docs/benchmarks/BENCHMARK_RESULTS_2025-11-23.md)
